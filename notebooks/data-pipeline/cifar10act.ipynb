{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "924064f2-7d9b-4a90-a4d1-679de5bc12a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 243 ms (started: 2022-09-16 23:02:13 -07:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autotime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63a75cf-f790-4b16-b8d9-67aca21c5ffc",
   "metadata": {},
   "source": [
    "**Note**: you should run the `cifar10.ipynb` notebook first, and store the cifar10 data for use here. If you don't, lots of the code here won't run. If you ended up here from searching the internet for how to run inference on cifar10 (or get activations) with pytorch and couldn't care less about `drnb`, you can definitely cobble together enough code to run inference on the version of cifar10 provided with the `torchvision` module.\n",
    "\n",
    "In the `cifar10` notebook I noted that this is not a dataset that embeds very well in its raw form, but that the activation layer of a convolutional neural network gave quite good results with [Barnes-Hut t-SNE](http://jmlr.org/papers/v15/vandermaaten14a.html). As [PyMDE](https://pymde.org/) uses pytorch as a dependency, that is a convenient library to use to generate some activation data of our own. However, although cifar10 is not a huge dataset by modern standards, it's still time-consuming for a normal person to train it. Fortunately, [Huy Phan](https://github.com/huyvnphan) trained some common CNN architectures with cifar10 *and* shared the weights at <https://github.com/huyvnphan/PyTorch_CIFAR10>. What a mensch!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db7d4db-7ae8-4dc9-92a4-d9824a896ef3",
   "metadata": {},
   "source": [
    "So we just have to build a network, download the weights, and then run inference with the network on the cifar10 images. That's not that hard. Nonetheless as a pytorch ignoramus, I had to refer to many a website to make this notebook work. If you want to follow in my footsteps:\n",
    "\n",
    "* <https://github.com/huyvnphan/PyTorch_CIFAR10>\n",
    "* <https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2021/05/27/extracting-features.html>\n",
    "* <https://jdhao.github.io/2022/03/18/torch_accelerate_batch_inference/>\n",
    "* <https://discuss.pytorch.org/t/same-input-to-same-trained-model-producing-different-results-each-time/6704>\n",
    "* <https://docs.databricks.com/_static/notebooks/deep-learning/pytorch-images.html>\n",
    "* <https://stackoverflow.com/questions/60018578/what-does-model-eval-do-in-pytorch>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f394726d-4bc1-46a0-81be-84a8ecbdb00c",
   "metadata": {},
   "source": [
    "## Defining a CNN architecture\n",
    "\n",
    "Which architecture to use? Consider this [recent Reddit comment](https://www.reddit.com/r/MachineLearning/comments/xe4fi6/comment/iofq54x/). It mentions VGG in conjunction with UMAP for clustering, and the [PyTorch_CIFAR10](https://github.com/huyvnphan/PyTorch_CIFAR10) put various flavors of that at the top of leaderboard. So we'll use that and specifically `vgg13_bn`.\n",
    "\n",
    "The code to do this is all [Huy Phan's work](https://github.com/huyvnphan/PyTorch_CIFAR10/blob/641cac24371b17052b9bb6e56af1c83b5e97cd7f/cifar10_models/vgg.py). However, I have simplified the code as we only need one architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49029965-660b-46c0-b1d4-724281cd52de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 455 ms (started: 2022-09-16 23:02:19 -07:00)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, classifier):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        # CIFAR 10 (7, 7) to (1, 1)\n",
    "        # self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def make_layers():\n",
    "    cfg = [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"]\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == \"M\":\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def make_classifier():\n",
    "    num_classes = 10\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(512 * 1 * 1, 4096),\n",
    "        # nn.Linear(512 * 7 * 7, 4096),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, 4096),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, num_classes),\n",
    "    )\n",
    "\n",
    "\n",
    "def load_weights(model, file, device=None):\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"Setting device to {device}\")\n",
    "    state_dict = torch.load(file, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "def vgg13_bn(weights_file, device=None):\n",
    "    \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\"\"\"\n",
    "    features = make_layers()\n",
    "    classifier = make_classifier()\n",
    "    model = VGG(features, classifier)\n",
    "\n",
    "    load_weights(model, weights_file, device=device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6771d6-2a1a-4547-8f31-80dce8b67c98",
   "metadata": {},
   "source": [
    "## Grab the pretrained weights and build the network\n",
    "\n",
    "Again, these weights are all from data pointed to from <https://github.com/huyvnphan/PyTorch_CIFAR10>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eae85873-8347-41a5-8795-c1342e8615ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 39.8 ms (started: 2022-09-16 23:02:22 -07:00)\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "def get_model(device=\"cpu\"):\n",
    "    url = \"https://rutgers.box.com/shared/static/gkw08ecs797j2et1ksmbg1w5t3idf5r5.zip\"\n",
    "    req = requests.get(url)\n",
    "    with zipfile.ZipFile(BytesIO(req.content)) as zip_file:\n",
    "        with zip_file.open(\"state_dicts/vgg13_bn.pt\") as weights_file:\n",
    "            return vgg13_bn(weights_file=weights_file, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "223d5846-03fc-4610-ba1d-0c6f7f83b5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 2s (started: 2022-09-16 23:03:01 -07:00)\n"
     ]
    }
   ],
   "source": [
    "# If you don't have a GPU use model_cpu instead\n",
    "# model_cpu = get_model(device=\"cpu\")\n",
    "model_cuda = get_model(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c551734-c02c-46e7-9192-8f4ec3a66d6a",
   "metadata": {},
   "source": [
    "## Create a dataset\n",
    "\n",
    "Adapting data for use with pytorch requires extending the [torch.utils.data.Dataset](https://pytorch.org/docs/stable/_modules/torch/utils/data/dataset.html#Dataset) class. You only need to implement two methods: `__len__` to return the number of items in the dataset, and `__getitem__`, which should return a specific item correctly transformed and ready to be shoved down the network. That means making it a [tensor](https://pytorch.org/docs/stable/tensors.html) and doing whatever scaling and centering was done to the training data. Fortunately the [CIFAR10 torchvision source](https://pytorch.org/vision/stable/_modules/torchvision/datasets/cifar.html#CIFAR10) is very clear to guide our efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86c4d197-615c-4090-91fc-145601742c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.32 s (started: 2022-09-16 23:04:28 -07:00)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms as T\n",
    "\n",
    "import drnb.io.dataset as drnb_data\n",
    "\n",
    "\n",
    "class Cifar10Dataset(torch.utils.data.Dataset):\n",
    "    # train=True: training; train=False: test; train=<int>: data[:train]; train=None: train+test\n",
    "    def __init__(self, train=None):\n",
    "        self.mean = (0.4914, 0.4822, 0.4465)\n",
    "        self.std = (0.2471, 0.2435, 0.2616)\n",
    "\n",
    "        drnb_cifar10 = drnb_data.read_data(\"cifar10\", sub_dir=\"data\")\n",
    "        if train is not None:\n",
    "            # must check if train is boolean first because booleans are also considered ints\n",
    "            if isinstance(train, bool):\n",
    "                if train:\n",
    "                    drnb_cifar10 = drnb_cifar10[:50000]\n",
    "                else:\n",
    "                    drnb_cifar10 = drnb_cifar10[50000:]\n",
    "            else:\n",
    "                drnb_cifar10 = drnb_cifar10[:train]\n",
    "        self.data = (\n",
    "            drnb_cifar10.astype(np.uint8)\n",
    "            .reshape(drnb_cifar10.shape[0], 3, 32, 32)\n",
    "            .transpose(0, 2, 3, 1)\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return T.Compose(\n",
    "            [\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(self.mean, self.std),\n",
    "            ]\n",
    "        )(self.data[index,])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "\n",
    "cifar10_dataset = Cifar10Dataset()\n",
    "len(cifar10_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1c8657-5ef9-41bd-bb5d-f8bfbf2bedae",
   "metadata": {},
   "source": [
    "Just check that we can still get back the original images and we haven't mangled the data as it was adapted to be a pytorch `Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51f1eb98-cb3f-4119-91ca-7203806351b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 75x75 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 529 ms (started: 2022-09-16 23:04:36 -07:00)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def view_cifar(cifar10, idx):\n",
    "    plt.figure(figsize=(0.75, 0.75))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(\n",
    "        cifar10.data[idx],\n",
    "        interpolation=\"nearest\",\n",
    "        vmin=0,\n",
    "        vmax=255,\n",
    "    )\n",
    "\n",
    "\n",
    "view_cifar(cifar10_dataset, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e358754f-a7bb-41c5-9558-1d92ade9d9d2",
   "metadata": {},
   "source": [
    "If you can see a blurry image of a frog, all is well. If you *can't*, you may actually still be ok: it's really not that easy to make out the cifar10 images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90de9381-152a-414f-9926-b98ef23718c2",
   "metadata": {},
   "source": [
    "## Using the torchvision CIFAR10 instead\n",
    "\n",
    "For debugging (or you just don't want to do the processing laid out in the `cifar10.ipynb` dataset yourself), you can use this function to use the torchvision cifar10 instead (it should give the same results). You must provide `root`, the path to where you want the data downloaded to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96e7928c-e280-42a4-a027-18d4a5aa6ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.72 ms (started: 2022-09-16 23:04:44 -07:00)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "\n",
    "def get_cifar10_tv(root, train=False):\n",
    "    mean = (0.4914, 0.4822, 0.4465)\n",
    "    std = (0.2471, 0.2435, 0.2616)\n",
    "    return CIFAR10(\n",
    "        root=root,\n",
    "        train=train,\n",
    "        transform=T.Compose(\n",
    "            [\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean, std),\n",
    "            ]\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f4266c-c747-417d-b3aa-2ca2d25bef5f",
   "metadata": {},
   "source": [
    "## Get the real labels\n",
    "\n",
    "If you use the pytorch `CIFAR10` class, the labels are returned as the second item of a tuple when you call e.g. `cifar10_tv[0]`. But I will use previously curated target data from `drnb`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7be318fd-d46f-4f16-b4fd-0fbbee29749b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 34.3 ms (started: 2022-09-16 23:04:52 -07:00)\n"
     ]
    }
   ],
   "source": [
    "cifar10_target = drnb_data.read_target(\"cifar10\", sub_dir=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de41a4b-7038-4b9e-b66b-664994a3aed8",
   "metadata": {},
   "source": [
    "## Find the activation layer\n",
    "\n",
    "Look at the `model_cuda`'s string representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceb28b2f-ea5c-4880-a534-493650aad04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (21): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (23): ReLU(inplace=True)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (30): ReLU(inplace=True)\n",
       "    (31): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.58 ms (started: 2022-09-16 23:04:55 -07:00)\n"
     ]
    }
   ],
   "source": [
    "model_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbec957e-d707-4a61-8d79-b665809e216b",
   "metadata": {},
   "source": [
    "I want the layer right before the `classifier` part: that's called `avgpool`. It's not really clear to me from the definition of `avgpool` itself what size it is, but the `Linear` layer straight after in the `classifier` section says `in_features=512`, so I guessed it consisted of `512` values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c9b817-701a-454e-96a3-1efcaa5c4dc4",
   "metadata": {},
   "source": [
    "## Making predictions\n",
    "\n",
    "Now to run inference with the model. Although inference is a lot faster than training, it's still slow on a CPU relative to a GPU. I estimate that if I had tried to do inference with the CPU on all of cifar10, it would have taken about ten minutes. Conversely on a GPU (a 1080 in a laptop, so hardly cutting edge) it only takes ten seconds. I recommend fiddling with `batch_size` and `num_workers` depending on your\n",
    "CPU or GPU. `batch_size` had the most noticeable effect.\n",
    "\n",
    "Because I am mainly interested in the activations, by default the activations are also returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1c0b4e8-4dba-4617-9b6e-f48576c9feff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.4 ms (started: 2022-09-16 23:05:11 -07:00)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def get_predictions(\n",
    "    model,\n",
    "    dataset,\n",
    "    device=None,\n",
    "    batch_size=None,\n",
    "    num_workers=None,\n",
    "    with_activations=True,\n",
    "):\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"Using device {device}\")\n",
    "    if device == \"cuda\":\n",
    "        model.cuda()\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        if num_workers is None:\n",
    "            num_workers = 2\n",
    "        if batch_size is None:\n",
    "            batch_size = 32\n",
    "        pin_memory = True\n",
    "    else:\n",
    "        dataloader_kwargs = dict(num_workers=0)\n",
    "        if num_workers is None:\n",
    "            num_workers = 0\n",
    "        if batch_size is None:\n",
    "            batch_size = 64\n",
    "    dataloader_kwargs = dict(\n",
    "        num_workers=num_workers, pin_memory=pin_memory, batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    device = torch.device(device)\n",
    "    data_loader = DataLoader(dataset, **dataloader_kwargs)\n",
    "\n",
    "    n_batches = len(data_loader)\n",
    "    n_predictions = len(dataset)\n",
    "\n",
    "    predicted_labels = np.empty(n_predictions, dtype=np.uint8)\n",
    "    # if you use the torchvision of Cifar10 you can get the actual labels back\n",
    "    # useful for debugging\n",
    "    actual_labels = np.empty(n_predictions, dtype=np.uint8)\n",
    "\n",
    "    # register a hook which will store the activation values for each batch\n",
    "    # this is where we need to know that `avgpool` is they layer we want to get data out of\n",
    "    activation_ndim = 512\n",
    "    activation_layer = {}\n",
    "    activations = None\n",
    "    if with_activations:\n",
    "        activations = np.empty((n_predictions, activation_ndim), dtype=np.float32)\n",
    "\n",
    "        def store_values(model, input, output):\n",
    "            activation_layer[\"values\"] = output.detach()\n",
    "\n",
    "        model.avgpool.register_forward_hook(store_values)\n",
    "\n",
    "    # loop through batches\n",
    "\n",
    "    model.eval()\n",
    "    batch_begin = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch_labels = None\n",
    "\n",
    "            # torchvision Cifar10 will return actual labels in the second item in the tuple\n",
    "            if isinstance(batch, list):\n",
    "                batch_labels = batch[1]\n",
    "                batch = batch[0]\n",
    "\n",
    "            actual_batch_size = batch.shape[0]\n",
    "            batch_end = batch_begin + actual_batch_size\n",
    "\n",
    "            # save the torchvision labels here\n",
    "            if batch_labels is not None:\n",
    "                actual_labels[batch_begin:batch_end] = batch_labels\n",
    "\n",
    "            predictions = model(batch.to(device))\n",
    "            predicted_labels[batch_begin:batch_end] = np.argmax(\n",
    "                predictions.detach().cpu().numpy().reshape((actual_batch_size, 10)),\n",
    "                axis=1,\n",
    "            )\n",
    "\n",
    "            if with_activations:\n",
    "                activations[batch_begin:batch_end] = (\n",
    "                    activation_layer[\"values\"]\n",
    "                    .cpu()\n",
    "                    .numpy()\n",
    "                    .reshape((actual_batch_size, activation_ndim))\n",
    "                )\n",
    "            batch_begin += actual_batch_size\n",
    "    if with_activations:\n",
    "        return predicted_labels, activations, actual_labels\n",
    "    return predicted_labels, actual_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cac720c-0c59-4f30-87f9-352be83d0ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.4 s (started: 2022-09-16 23:05:14 -07:00)\n"
     ]
    }
   ],
   "source": [
    "predicted_labels, activations, _ = get_predictions(\n",
    "    model_cuda, cifar10_dataset, device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d75cd1-19f9-4999-a4be-ff949aed610a",
   "metadata": {},
   "source": [
    "Let's just check the accuracy of the predictions to make sure the activations aren't completely hopeless:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7c9f52b-c4b4-463e-ba1b-8e3b30d4d654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99015"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.93 ms (started: 2022-09-16 23:05:45 -07:00)\n"
     ]
    }
   ],
   "source": [
    "np.sum(predicted_labels == cifar10_target[\"labels\"]) / len(cifar10_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb19d10-cdb5-4308-82c5-0bb606bb08a3",
   "metadata": {},
   "source": [
    "Yeah, that seems pretty good. Note that we are using the combined training and test set here. Prediction on just the test set is \"only\" 94%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d39d9e62-8783-4d09-ba93-c89244b58116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9421"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.47 s (started: 2022-09-16 23:05:48 -07:00)\n"
     ]
    }
   ],
   "source": [
    "predicted_test_labels, _ = get_predictions(\n",
    "    model_cuda, Cifar10Dataset(train=False), device=\"cuda\", with_activations=False\n",
    ")\n",
    "np.sum(predicted_test_labels == cifar10_target[50000:][\"labels\"]) / 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23000504-8b08-430b-a099-b03f5e79c46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 512),\n",
       " array([0.        , 0.        , 0.00283639, 0.        , 0.00380663,\n",
       "        0.00815624, 0.        , 0.        , 0.00249664, 0.        ],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.61 ms (started: 2022-09-16 23:05:55 -07:00)\n"
     ]
    }
   ],
   "source": [
    "activations.shape, activations[0, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4386ad-b753-4a38-b61b-220704e134e8",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d3a1a46-23ed-42a9-9651-c381321c7a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[23:11:24] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Requesting one extra neighbor to account for self-neighbor                      <a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">pipeline.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py#392\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">392</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[23:11:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Requesting one extra neighbor to account for self-neighbor                      \u001b]8;id=612757;file:///home/james/dev/drnb/src/drnb/io/pipeline.py\u001b\\\u001b[2mpipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=963405;file:///home/james/dev/drnb/src/drnb/io/pipeline.py#392\u001b\\\u001b[2m392\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Initial data shape: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">)</span>                                                 <a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">pipeline.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py#80\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">80</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initial data shape: \u001b[1m(\u001b[0m\u001b[1;36m60000\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m                                                 \u001b]8;id=442815;file:///home/james/dev/drnb/src/drnb/io/pipeline.py\u001b\\\u001b[2mpipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=984249;file:///home/james/dev/drnb/src/drnb/io/pipeline.py#80\u001b\\\u001b[2m80\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Keeping all columns                                                            <a href=\"file:///home/james/dev/drnb/src/drnb/preprocess.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">preprocess.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/preprocess.py#62\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">62</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Keeping all columns                                                            \u001b]8;id=531932;file:///home/james/dev/drnb/src/drnb/preprocess.py\u001b\\\u001b[2mpreprocess.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=288844;file:///home/james/dev/drnb/src/drnb/preprocess.py#62\u001b\\\u001b[2m62\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Data shape after filtering columns: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">)</span>                                <a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">pipeline.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py#151\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">151</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Data shape after filtering columns: \u001b[1m(\u001b[0m\u001b[1;36m60000\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m                                \u001b]8;id=737112;file:///home/james/dev/drnb/src/drnb/io/pipeline.py\u001b\\\u001b[2mpipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=194623;file:///home/james/dev/drnb/src/drnb/io/pipeline.py#151\u001b\\\u001b[2m151\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Removing rows with NAs                                                          <a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">pipeline.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py#135\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Removing rows with NAs                                                          \u001b]8;id=997251;file:///home/james/dev/drnb/src/drnb/io/pipeline.py\u001b\\\u001b[2mpipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=817839;file:///home/james/dev/drnb/src/drnb/io/pipeline.py#135\u001b\\\u001b[2m135\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Data shape after filtering NAs: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">)</span>                                    <a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">pipeline.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py#146\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Data shape after filtering NAs: \u001b[1m(\u001b[0m\u001b[1;36m60000\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m                                    \u001b]8;id=246934;file:///home/james/dev/drnb/src/drnb/io/pipeline.py\u001b\\\u001b[2mpipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=252534;file:///home/james/dev/drnb/src/drnb/io/pipeline.py#146\u001b\\\u001b[2m146\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[23:11:25] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Checked for duplicates: found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                 <a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">pipeline.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py#158\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">158</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[23:11:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Checked for duplicates: found \u001b[1;36m0\u001b[0m                                                 \u001b]8;id=564075;file:///home/james/dev/drnb/src/drnb/io/pipeline.py\u001b\\\u001b[2mpipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=215412;file:///home/james/dev/drnb/src/drnb/io/pipeline.py#158\u001b\\\u001b[2m158\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> No scaling                                                                     <a href=\"file:///home/james/dev/drnb/src/drnb/preprocess.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">preprocess.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/preprocess.py#25\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">25</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m No scaling                                                                     \u001b]8;id=35808;file:///home/james/dev/drnb/src/drnb/preprocess.py\u001b\\\u001b[2mpreprocess.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=214958;file:///home/james/dev/drnb/src/drnb/preprocess.py#25\u001b\\\u001b[2m25\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Converting to numpy with <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'dtype'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'float32'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'layout'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'c'</span><span style=\"font-weight: bold\">}</span>                    <a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">pipeline.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py#163\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Converting to numpy with \u001b[1m{\u001b[0m\u001b[32m'dtype'\u001b[0m: \u001b[32m'float32'\u001b[0m, \u001b[32m'layout'\u001b[0m: \u001b[32m'c'\u001b[0m\u001b[1m}\u001b[0m                    \u001b]8;id=929188;file:///home/james/dev/drnb/src/drnb/io/pipeline.py\u001b\\\u001b[2mpipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=697551;file:///home/james/dev/drnb/src/drnb/io/pipeline.py#163\u001b\\\u001b[2m163\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Writing data for cifar10act                                                     <a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">pipeline.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py#225\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">225</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Writing data for cifar10act                                                     \u001b]8;id=583612;file:///home/james/dev/drnb/src/drnb/io/pipeline.py\u001b\\\u001b[2mpipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=194981;file:///home/james/dev/drnb/src/drnb/io/pipeline.py#225\u001b\\\u001b[2m225\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[23:12:22] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Processing target with initial shape <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>                                 <a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">pipeline.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py#196\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">196</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[23:12:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Processing target with initial shape \u001b[1m(\u001b[0m\u001b[1;36m60000\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m                                 \u001b]8;id=967272;file:///home/james/dev/drnb/src/drnb/io/pipeline.py\u001b\\\u001b[2mpipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=265895;file:///home/james/dev/drnb/src/drnb/io/pipeline.py#196\u001b\\\u001b[2m196\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Keeping all columns                                                            <a href=\"file:///home/james/dev/drnb/src/drnb/preprocess.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">preprocess.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/preprocess.py#62\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">62</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Keeping all columns                                                            \u001b]8;id=927351;file:///home/james/dev/drnb/src/drnb/preprocess.py\u001b\\\u001b[2mpreprocess.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=133746;file:///home/james/dev/drnb/src/drnb/preprocess.py#62\u001b\\\u001b[2m62\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Writing target for cifar10act                                                   <a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">pipeline.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py#225\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">225</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Writing target for cifar10act                                                   \u001b]8;id=561254;file:///home/james/dev/drnb/src/drnb/io/pipeline.py\u001b\\\u001b[2mpipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=854384;file:///home/james/dev/drnb/src/drnb/io/pipeline.py#225\u001b\\\u001b[2m225\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Calculating nearest neighbors                                                   <a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">pipeline.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py#240\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">240</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Calculating nearest neighbors                                                   \u001b]8;id=938343;file:///home/james/dev/drnb/src/drnb/io/pipeline.py\u001b\\\u001b[2mpipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=140219;file:///home/james/dev/drnb/src/drnb/io/pipeline.py#240\u001b\\\u001b[2m240\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Finding <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">151</span> neighbors using faiss with euclidean metric and params: <span style=\"font-weight: bold\">{}</span>           <a href=\"file:///home/james/dev/drnb/src/drnb/neighbors/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/neighbors/__init__.py#71\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">71</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Finding \u001b[1;36m151\u001b[0m neighbors using faiss with euclidean metric and params: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m           \u001b]8;id=228505;file:///home/james/dev/drnb/src/drnb/neighbors/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=463257;file:///home/james/dev/drnb/src/drnb/neighbors/__init__.py#71\u001b\\\u001b[2m71\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading faiss with AVX2 support.                                                   <a href=\"file:///home/james/dev/drnb/venv/lib/python3.10/site-packages/faiss/loader.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">loader.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/venv/lib/python3.10/site-packages/faiss/loader.py#54\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">54</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading faiss with AVX2 support.                                                   \u001b]8;id=132062;file:///home/james/dev/drnb/venv/lib/python3.10/site-packages/faiss/loader.py\u001b\\\u001b[2mloader.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=221143;file:///home/james/dev/drnb/venv/lib/python3.10/site-packages/faiss/loader.py#54\u001b\\\u001b[2m54\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Could not load library with AVX2 support due to:                                   <a href=\"file:///home/james/dev/drnb/venv/lib/python3.10/site-packages/faiss/loader.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">loader.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/venv/lib/python3.10/site-packages/faiss/loader.py#58\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">58</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ModuleNotFoundError</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"No module named 'faiss.swigfaiss_avx2'\"</span><span style=\"font-weight: bold\">)</span>                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Could not load library with AVX2 support due to:                                   \u001b]8;id=958328;file:///home/james/dev/drnb/venv/lib/python3.10/site-packages/faiss/loader.py\u001b\\\u001b[2mloader.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=238353;file:///home/james/dev/drnb/venv/lib/python3.10/site-packages/faiss/loader.py#58\u001b\\\u001b[2m58\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1;35mModuleNotFoundError\u001b[0m\u001b[1m(\u001b[0m\u001b[32m\"No module named 'faiss.swigfaiss_avx2'\"\u001b[0m\u001b[1m)\u001b[0m                      \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading faiss.                                                                     <a href=\"file:///home/james/dev/drnb/venv/lib/python3.10/site-packages/faiss/loader.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">loader.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/venv/lib/python3.10/site-packages/faiss/loader.py#64\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">64</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading faiss.                                                                     \u001b]8;id=849835;file:///home/james/dev/drnb/venv/lib/python3.10/site-packages/faiss/loader.py\u001b\\\u001b[2mloader.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=689730;file:///home/james/dev/drnb/venv/lib/python3.10/site-packages/faiss/loader.py#64\u001b\\\u001b[2m64\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Successfully loaded faiss.                                                         <a href=\"file:///home/james/dev/drnb/venv/lib/python3.10/site-packages/faiss/loader.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">loader.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/venv/lib/python3.10/site-packages/faiss/loader.py#66\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">66</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Successfully loaded faiss.                                                         \u001b]8;id=947304;file:///home/james/dev/drnb/venv/lib/python3.10/site-packages/faiss/loader.py\u001b\\\u001b[2mloader.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=826119;file:///home/james/dev/drnb/venv/lib/python3.10/site-packages/faiss/loader.py#66\u001b\\\u001b[2m66\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[23:13:37] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Calculating triplets                                                            <a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">pipeline.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py#276\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">276</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[23:13:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Calculating triplets                                                            \u001b]8;id=356112;file:///home/james/dev/drnb/src/drnb/io/pipeline.py\u001b\\\u001b[2mpipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=697549;file:///home/james/dev/drnb/src/drnb/io/pipeline.py#276\u001b\\\u001b[2m276\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[23:13:43] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Writing csv format to triplets/cifar10act.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.1337</span>.idx.csv                        <a href=\"file:///home/james/dev/drnb/src/drnb/io/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/io/__init__.py#221\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">221</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[23:13:43]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Writing csv format to triplets/cifar10act.\u001b[1;36m5.1337\u001b[0m.idx.csv                        \u001b]8;id=972755;file:///home/james/dev/drnb/src/drnb/io/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=891660;file:///home/james/dev/drnb/src/drnb/io/__init__.py#221\u001b\\\u001b[2m221\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[23:13:45] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Writing csv format to triplets/cifar10act.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.1337</span>.l2.csv                         <a href=\"file:///home/james/dev/drnb/src/drnb/io/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/io/__init__.py#221\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">221</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[23:13:45]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Writing csv format to triplets/cifar10act.\u001b[1;36m5.1337\u001b[0m.l2.csv                         \u001b]8;id=205748;file:///home/james/dev/drnb/src/drnb/io/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=943076;file:///home/james/dev/drnb/src/drnb/io/__init__.py#221\u001b\\\u001b[2m221\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[23:13:49] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Writing numpy format to triplets/cifar10act.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.1337</span>.idx.npy                      <a href=\"file:///home/james/dev/drnb/src/drnb/io/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/io/__init__.py#244\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">244</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[23:13:49]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Writing numpy format to triplets/cifar10act.\u001b[1;36m5.1337\u001b[0m.idx.npy                      \u001b]8;id=706872;file:///home/james/dev/drnb/src/drnb/io/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=15976;file:///home/james/dev/drnb/src/drnb/io/__init__.py#244\u001b\\\u001b[2m244\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Writing numpy format to triplets/cifar10act.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.1337</span>.l2.npy                       <a href=\"file:///home/james/dev/drnb/src/drnb/io/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/io/__init__.py#244\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">244</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Writing numpy format to triplets/cifar10act.\u001b[1;36m5.1337\u001b[0m.l2.npy                       \u001b]8;id=37243;file:///home/james/dev/drnb/src/drnb/io/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=180676;file:///home/james/dev/drnb/src/drnb/io/__init__.py#244\u001b\\\u001b[2m244\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[23:13:50] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Writing pipeline result for cifar10act                                          <a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">pipeline.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/james/dev/drnb/src/drnb/io/pipeline.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[23:13:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Writing pipeline result for cifar10act                                          \u001b]8;id=926424;file:///home/james/dev/drnb/src/drnb/io/pipeline.py\u001b\\\u001b[2mpipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=573916;file:///home/james/dev/drnb/src/drnb/io/pipeline.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 29s (started: 2022-09-16 23:11:20 -07:00)\n"
     ]
    }
   ],
   "source": [
    "from drnb.io.pipeline import create_default_pipeline\n",
    "\n",
    "data_result = create_default_pipeline(check_for_duplicates=True).run(\n",
    "    \"cifar10act\",\n",
    "    data=activations,\n",
    "    target=cifar10_target,\n",
    "    tags=[\"activations\"],\n",
    "    url=\"https://github.com/huyvnphan/PyTorch_CIFAR10\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b350e8f-b80e-4a7c-835e-ca531f6eb97c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
